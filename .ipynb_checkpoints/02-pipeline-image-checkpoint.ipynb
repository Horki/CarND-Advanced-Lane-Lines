{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image Pipeline\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Apply a distortion correction to raw images.\n",
    "* Undistort image\n",
    "* Unwrap undistorted image\n",
    "* Grad binary unwraped image\n",
    "* HLS from grad binary image\n",
    "\n",
    "---\n",
    "## Globals and libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'examples/wide_dist_pickle.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8b5ca659c639>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# get mtx, dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdist_pickle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"examples/wide_dist_pickle.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mmtx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist_pickle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mtx\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist_pickle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dist\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'examples/wide_dist_pickle.p'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import pickle\n",
    "%matplotlib qt\n",
    "\n",
    "# get images\n",
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "# get mtx, dist\n",
    "dist_pickle = pickle.load( open( \"examples/wide_dist_pickle.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_undistort(img):\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist\n",
    "\n",
    "\n",
    "def warper(img, src, dst):\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_NEAREST)\n",
    "    return warped\n",
    "\n",
    "\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', thresh_min=0, thresh_max=255):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "    # Return the result\n",
    "    return binary_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example of distortion-corrected image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test_images/straight_lines1.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "undistort = cal_undistort(gray)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(gray)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(undistort)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "plt.savefig('output_images/undistorted_image.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unwraped image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w = undistort.shape[:2]\n",
    "\n",
    "src = np.float32([(575,464),\n",
    "                  (707,464), \n",
    "                  (258,682), \n",
    "                  (1049,682)])\n",
    "\n",
    "dst = np.float32([(450,0),\n",
    "                  (w-450,0),\n",
    "                  (450,h),\n",
    "                  (w-450,h)])\n",
    "\n",
    "unwarped = warper(undistort, src, dst)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(undistort)\n",
    "ax1.set_title('Undistorted Image', fontsize=50)\n",
    "ax2.imshow(unwarped)\n",
    "ax2.set_title('Unwarped Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "plt.savefig('output_images/unwarped_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Color Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = unwarped[:,:,0]\n",
    "G = unwarped[:,:,1]\n",
    "B = unwarped[:,:,2]\n",
    "thresh = (200, 255)\n",
    "binary = np.zeros_like(R)\n",
    "binary[(R > thresh[0]) & (R <= thresh[1])] = 1\n",
    "\n",
    "# Save binary\n",
    "plt.imshow(binary, cmap='gray')\n",
    "# plt.savefig('output_images/binary.jpg')\n",
    "\n",
    "# Show pictures\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(unwarped)\n",
    "ax1.set_title('Unwraped Image', fontsize=50)\n",
    "ax2.imshow(binary, cmap='gray')\n",
    "ax2.set_title('Grad Binary', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "# plt.savefig('output_images/grad_binary.jpg')\n",
    "\n",
    "hls = cv2.cvtColor(unwarped, cv2.COLOR_RGB2HLS)\n",
    "H = hls[:,:,0]\n",
    "L = hls[:,:,1]\n",
    "S = hls[:,:,2]\n",
    "thresh = (15, 100)\n",
    "h_binary = np.zeros_like(H)\n",
    "h_binary[(H > thresh[0]) & (H <= thresh[1])] = 1\n",
    "\n",
    "l_binary = np.zeros_like(L)\n",
    "l_binary[(L > thresh[0]) & (L <= thresh[1])] = 1\n",
    "\n",
    "thresh = (90, 255)\n",
    "s_binary = np.zeros_like(S)\n",
    "s_binary[(S > thresh[0]) & (S <= thresh[1])] = 1\n",
    "\n",
    "\n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(unwarped)\n",
    "ax1.set_title('Unwraped Image', fontsize=30)\n",
    "\n",
    "ax2.imshow(h_binary, cmap='gray')\n",
    "ax2.set_title('H Binary', fontsize=30)\n",
    "\n",
    "ax3.imshow(l_binary, cmap='gray')\n",
    "ax3.set_title('L Binary', fontsize=30)\n",
    "\n",
    "ax4.imshow(s_binary, cmap='gray')\n",
    "ax4.set_title('S Binary', fontsize=30)\n",
    "\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "# plt.savefig('output_images/hls_binary.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sobel Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_x = abs_sobel_thresh(unwarped, orient='x', thresh_min=20, thresh_max=100)\n",
    "sobel_y = abs_sobel_thresh(unwarped, orient='y', thresh_min=20, thresh_max=100)\n",
    "sobel_mag = mag_thresh(unwarped, sobel_kernel=3, mag_thresh=(30, 100))\n",
    "sobel_dir = dir_threshold(unwarped, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "\n",
    "f, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(unwarped)\n",
    "ax1.set_title('Unwraped Image', fontsize=20)\n",
    "\n",
    "ax2.imshow(sobel_x, cmap='gray')\n",
    "ax2.set_title('Thresholded Gradient x orient', fontsize=20)\n",
    "\n",
    "ax3.imshow(sobel_y, cmap='gray')\n",
    "ax3.set_title('Thresholded Gradient y orient', fontsize=20)\n",
    "\n",
    "ax4.imshow(sobel_mag, cmap='gray')\n",
    "ax4.set_title('Thresholded Magnitude xy orient', fontsize=20)\n",
    "\n",
    "ax5.imshow(sobel_dir, cmap='gray')\n",
    "ax5.set_title('Thresholded Grad. Dir.', fontsize=20)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "plt.savefig('output_images/sobels.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding the lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
